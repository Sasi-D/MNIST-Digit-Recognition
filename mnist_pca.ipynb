{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy\n",
    "import math\n",
    "\n",
    "'''\n",
    "------------------------------------------------------------------------------------------------------------\n",
    "    STARTER CODE AND FUNCTIONS\n",
    "------------------------------------------------------------------------------------------------------------\n",
    "'''\n",
    "dataset = load_dataset(\"mnist\")\n",
    "\n",
    "#Getting random 100 sample images of each label from 'mnist' dataset\n",
    "sample_images = []\n",
    "for i in range(10):\n",
    "    cur_digit_images = []\n",
    "    for train_image in dataset['train']:\n",
    "        if train_image['label'] == i:\n",
    "            cur_digit_images.append(train_image)\n",
    "    random_cur_digit_images = random.sample(cur_digit_images, 100) #Taking random 100 images\n",
    "    sample_images.extend(random_cur_digit_images)\n",
    "\n",
    "#Flattening images as 1-D list\n",
    "flatten_images = []\n",
    "for image in sample_images:\n",
    "    flatten_image = []\n",
    "    image_data = image['image'].getdata()\n",
    "    for pixel in image_data:\n",
    "        flatten_image.append(pixel)\n",
    "    flatten_images.append(flatten_image)\n",
    "\n",
    "#Converting flatten_images as numpy array and forcing it to use float64 for better precision\n",
    "flatten_images = numpy.array(flatten_images)\n",
    "flatten_images = [numpy.ravel(numpy.asarray(x,dtype=numpy.float64)) for x in flatten_images]\n",
    "flatten_images = numpy.array(flatten_images)\n",
    "\n",
    "#Centering flatten_images\n",
    "mean = numpy.mean(flatten_images, axis = 0)\n",
    "centered_images = flatten_images - mean\n",
    "\n",
    "#Transposing as we need the each data point to be along a column\n",
    "centered_images = centered_images.T\n",
    "\n",
    "print(\"******** Got the train dataset and Centered it **********\\n\")\n",
    "\n",
    "\n",
    "#Function to get eigen values and vectors in decending order\n",
    "def get_eigen_values_and_vectors(matrix):\n",
    "    eigen_vals , eigen_vecs = numpy.linalg.eigh(matrix)\n",
    "    #eigh gives eigen values in ascending order hence inversing them accordingly\n",
    "    eigen_vals = eigen_vals[::-1]\n",
    "    eigen_vecs = eigen_vecs[:, ::-1]\n",
    "    return (eigen_vals, eigen_vecs)\n",
    "\n",
    "# Calculating the Covariance Matrix\n",
    "covariance_matrix = numpy.dot(centered_images, centered_images.T) / 1000\n",
    "\n",
    "# Getting required sorted eigen vectors and eigen values\n",
    "eigen_values, eigen_vectors = get_eigen_values_and_vectors(covariance_matrix)\n",
    "\n",
    "print(\"****** Got eigen values and vectors ******\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "------------------------------------------------------------------------------------------------------------\n",
    "    PART (i)\n",
    "------------------------------------------------------------------------------------------------------------\n",
    "'''\n",
    "total_variance = numpy.sum(eigen_values)\n",
    "\n",
    "#Writing Variance due to each PC into txt file\n",
    "with open('principal_component_variance.txt', 'w') as f:\n",
    "    for i, variance in enumerate(eigen_values):\n",
    "        #Due to floating point representations some 0's will come as very very small -ve values hence making them 0.\n",
    "        if variance < 0 :\n",
    "            variance = 0\n",
    "        ratio = (variance / total_variance) * 100\n",
    "        f.write(f\"Variance explained by PC{i+1} : {ratio} %\\n\")\n",
    "print(\"Printed the Variance explained by PC's to *principal_component_variance.txt* file\\n\")\n",
    "\n",
    "#Plotting images of Principle Components\n",
    "plt.figure(figsize=(30, 50))\n",
    "for i in range(150):\n",
    "    plt.subplot(16, 10, i+1)\n",
    "    pc_image = eigen_vectors[:, i].reshape(28, 28) # Eigen vectors i.e principle components are arranged column-wise\n",
    "    plt.imshow(pc_image, cmap='gray')\n",
    "    plt.title(f'PC {i + 1}')\n",
    "    plt.axis('off')\n",
    "plt.subplots_adjust(top=0.96)\n",
    "plt.suptitle('Top 150 Principal Components Images', fontsize=40)\n",
    "plt.savefig(\"PC's_Images.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "----------------------------------------------------------------------------------------------------------------\n",
    "    PART (ii)\n",
    "----------------------------------------------------------------------------------------------------------------\n",
    "'''\n",
    "\n",
    "# A function to return a random flattened test image\n",
    "def get_random_test_image():\n",
    "    test_image = None\n",
    "    flatten_test_img = []\n",
    "    label = random.randint(0, 9) #Selecting a random label\n",
    "    for img in dataset['test']:\n",
    "        if img['label'] == label:\n",
    "            test_image = img\n",
    "            break\n",
    "    test_image_data = test_image['image'].getdata()\n",
    "    for pixel in test_image_data:\n",
    "        flatten_test_img.append(pixel)\n",
    "    flatten_test_img = numpy.array(flatten_test_img)\n",
    "    return flatten_test_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_components = [10, 30, 50, 130, 200, 300, 500, 784]\n",
    "num_plots = len(n_components)\n",
    "fig, axs = plt.subplots(2, 4, figsize=(15, 6))\n",
    "\n",
    "flatten_test_img = get_random_test_image()\n",
    "centered_test_img = flatten_test_img - mean\n",
    "\n",
    "for i, n in enumerate(n_components):\n",
    "    projected_image = []\n",
    "    #Getting the projected image using 'n' principle components\n",
    "    for j in range(n):\n",
    "        projection_length = (numpy.dot(centered_test_img,eigen_vectors[:, j].T))\n",
    "        if len(projected_image) == 0:\n",
    "            projected_image = numpy.dot(projection_length, eigen_vectors[:, j].T)\n",
    "        else:\n",
    "            projected_image += numpy.dot(projection_length, eigen_vectors[:, j].T)\n",
    "    #Getting back the original Image by adding mean\n",
    "    projected_image = projected_image + mean    \n",
    "    reconstructed_img = projected_image.reshape(28,28)\n",
    "    \n",
    "    # Plotting the reconstructed image\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    axs[row, col].imshow(reconstructed_img, cmap='gray')\n",
    "    axs[row, col].set_title(f'PCs = {n}')\n",
    "    axs[row, col].axis('off') \n",
    "plt.suptitle(\"Test Image Reconstruction using various number of PC's\")\n",
    "plt.tight_layout() \n",
    "plt.savefig('Reconstructed_image.png')\n",
    "print(\"Saved Reconstructed Image by varying number of PC's to file named 'Reconstructed_image.png'\\n\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Calculating # of PC's to get to 95% of Variance\n",
    "count = 0\n",
    "current_sum = 0.0\n",
    "for item in eigen_values:\n",
    "    current_sum += item\n",
    "    count += 1\n",
    "    if (current_sum/total_variance) >= 0.95:\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(\"Minimum required 'd' to classify the different digits correctly :\", count, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "----------------------------------------------------------------------------------------------------------\n",
    "    FUNCTIONS FOR PART (iii)\n",
    "----------------------------------------------------------------------------------------------------------\n",
    "'''\n",
    "\n",
    "def get_polynomial_kernel_matrix(d):\n",
    "    kernel_matrix = numpy.zeros((1000, 1000))\n",
    "    for i in range(1000):\n",
    "        for j in range(1000):\n",
    "            kernel_matrix[i][j] = (1 + numpy.dot(flatten_images[i],flatten_images[j].T)) ** d\n",
    "    return kernel_matrix\n",
    "\n",
    "def get_radial_kernel_matrix(sigma):\n",
    "    kernel_matrix = numpy.zeros((1000, 1000))\n",
    "    for i in range(1000):\n",
    "        for j in range(1000):\n",
    "            kernel_matrix[i][j] = math.exp(-1*(numpy.dot(((flatten_images[i]-flatten_images[j]).T),(flatten_images[i]-flatten_images[j])))/(2*(math.pow(sigma,2))))\n",
    "    return kernel_matrix\n",
    "\n",
    "def get_centered_kernel_matrix(kernel_matrix):\n",
    "    kernel_matrix_rows_sum = numpy.zeros(1000)\n",
    "    kernel_matrix_total_sum = 0\n",
    "    for i in range(1000):\n",
    "        for j in range(1000):\n",
    "            kernel_matrix_rows_sum[i] += kernel_matrix[i][j]\n",
    "            kernel_matrix_total_sum += kernel_matrix[i][j]\n",
    "            \n",
    "    centered_kernel_matrix = numpy.zeros((1000, 1000))\n",
    "    for i in range(1000):\n",
    "        for j in range(1000):\n",
    "            centered_kernel_matrix[i][j] = kernel_matrix[i][j] - ((kernel_matrix_rows_sum[i])/1000) - ((kernel_matrix_rows_sum[j])/1000) + kernel_matrix_total_sum/1000000 \n",
    "    \n",
    "    return centered_kernel_matrix\n",
    "\n",
    "\n",
    "def get_kernel_matrix_eigen_values_and_vectors(d, poly_or_kernel):\n",
    "    if poly_or_kernel == 1:\n",
    "        kernel_matrix = get_polynomial_kernel_matrix(d)\n",
    "    else:\n",
    "        kernel_matrix = get_radial_kernel_matrix(d)\n",
    "    centered_kernel_matrix = get_centered_kernel_matrix(kernel_matrix)\n",
    "    kernel_matrix_eigen_vals, kernel_matrix_eigen_vecs = get_eigen_values_and_vectors(centered_kernel_matrix)\n",
    "    return (kernel_matrix_eigen_vals, kernel_matrix_eigen_vecs)\n",
    "\n",
    "\n",
    "#Function to get projection lengths of first 2 Principle Components\n",
    "def get_PC1_PC2_lengths(d, poly_or_kernel):\n",
    "    kernel_matrix_eigen_vals, kernel_matrix_eigen_vecs = get_kernel_matrix_eigen_values_and_vectors(d, poly_or_kernel)\n",
    "    \n",
    "    # Calculating alpha_k \n",
    "    alpha_k = []\n",
    "    for i in range(len(kernel_matrix_eigen_vals)):\n",
    "        root_n_lamda = numpy.sqrt(abs(kernel_matrix_eigen_vals[i]))\n",
    "        alpha_k_i = numpy.divide(kernel_matrix_eigen_vecs[:, i], root_n_lamda)\n",
    "        alpha_k.append(alpha_k_i)\n",
    "    alpha_k = numpy.array(alpha_k)\n",
    " \n",
    "    #Getting the Kernel Matrix\n",
    "    if poly_or_kernel == 1:\n",
    "        kernel_matrix = get_polynomial_kernel_matrix(d)\n",
    "    else:\n",
    "        kernel_matrix = get_radial_kernel_matrix(d)\n",
    "\n",
    "    #As kernel function is symmentric\n",
    "    projection_length_PC1 = []\n",
    "    for i in range(1000):\n",
    "        projection_length_PC1.append(numpy.dot(alpha_k[0], kernel_matrix[i]))\n",
    "\n",
    "    projection_length_PC2 = []\n",
    "    for i in range(1000):\n",
    "        projection_length_PC2.append(numpy.dot(alpha_k[1], kernel_matrix[i]))\n",
    "    \n",
    "    return (projection_length_PC1, projection_length_PC2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "    PART (iii)\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "'''\n",
    "\n",
    "# Ploting using polynomial kernel\n",
    "d_list = [2, 3, 4]\n",
    "plt.figure(figsize = (14, 11))\n",
    "for i,d in enumerate(d_list):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    pc1_length, pc2_length = get_PC1_PC2_lengths(d, 1) # 1 here means polynomial\n",
    "    plt.scatter(pc1_length, pc2_length, label = '(X, Y)', alpha = 0.8)\n",
    "    plt.xlabel(\"X -> Projection length's due to PC1\")\n",
    "    plt.ylabel(\"Y -> Projection length's due to PC2\")\n",
    "    plt.title(f\"Plot for Polynomial kernel function by taking d={d}\")\n",
    "    plt.legend()\n",
    "plt.savefig('Polynomial_Kernel_Projection.png')\n",
    "print(\"Saved the plot of projection of each point in the dataset onto the top-2 components using polynomial kernel to 'Polynomial_kernel_Projection.png'\\n\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Plotting using radial kernel\n",
    "sigma_list = [2, 10, 100, 1000]\n",
    "\n",
    "plt.figure(figsize=(15,16))\n",
    "for i, sigma in enumerate(sigma_list):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    pc1_length, pc2_length = get_PC1_PC2_lengths(sigma, 2)\n",
    "    plt.scatter(pc1_length, pc2_length, label = '(X, Y)', alpha = 0.8)\n",
    "    plt.xlabel(\"X -> Projection length's due to PC1\")\n",
    "    plt.ylabel(\"Y -> Projection length's due to PC2\")\n",
    "    plt.title(f\"Plot for Radial kernel function by taking sigma={sigma}\")\n",
    "    plt.legend()\n",
    "plt.savefig('Radial_kernel_Projection.png')\n",
    "print(\"Saved the plot of projection of each point in the dataset onto the top-2 components using Radial kernel to 'Radial_kernel_Projection.png'\\n\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
